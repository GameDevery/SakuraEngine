#include "SkrGraphics/api.h"
#include "SkrRenderGraph/phases_v2/schedule_timeline.hpp"
#include "SkrRenderGraph/frontend/pass_node.hpp"
#include "SkrRenderGraph/frontend/resource_node.hpp"

namespace skr {
namespace render_graph {

ScheduleTimeline::ScheduleTimeline(const ScheduleTimelineConfig& cfg)
    : config(cfg)
{
}

ScheduleTimeline::~ScheduleTimeline() = default;

void ScheduleTimeline::on_initialize(RenderGraph* graph) SKR_NOEXCEPT
{
    // æŸ¥è¯¢é˜Ÿåˆ—èƒ½åŠ›
    query_queue_capabilities(graph);
    
    // åˆå§‹åŒ–è°ƒåº¦ç»“æœ
    schedule_result.queue_schedules.clear();
    schedule_result.sync_requirements.clear(); 
    schedule_result.pass_queue_assignments.clear();
}

void ScheduleTimeline::on_finalize(RenderGraph* graph) SKR_NOEXCEPT
{
    // æ¸…ç†åˆ†é…çš„Fenceèµ„æº
    for (auto& requirement : schedule_result.sync_requirements) {
        if (requirement.fence) {
            cgpu_free_fence(requirement.fence);
            requirement.fence = nullptr;
        }
    }
    
    // æ¸…ç†æ‰€æœ‰çŠ¶æ€
    clear_frame_data();
}

void ScheduleTimeline::clear_frame_data() SKR_NOEXCEPT
{
    // æ¸…ç†è°ƒåº¦ç»“æœ
    schedule_result.queue_schedules.clear();
    schedule_result.sync_requirements.clear();
    schedule_result.pass_queue_assignments.clear();
    
    // æ¸…ç†æ¯å¸§é‡å»ºçš„æ•°æ®
    dependency_info.clear();
    pass_to_queue.clear();
    pass_preferred_queue.clear();
}

void ScheduleTimeline::on_execute(RenderGraph* graph, RenderGraphProfiler* profiler) SKR_NOEXCEPT
{
    SKR_LOG_DEBUG(u8"ScheduleTimeline: Starting timeline scheduling and fence allocation");
    
    // 0. æ¸…ç©ºä¸Šä¸€å¸§çš„æ•°æ® - RGä¸­çš„èµ„æºå’ŒPassæ¯å¸§éƒ½ä¸ç¨³å®š
    clear_frame_data();
    
    // 1. åˆ†æPassä¾èµ–å…³ç³»
    analyze_dependencies(graph);
    
    // 2. å¯¹Passè¿›è¡Œåˆ†ç±»
    classify_passes(graph);
    
    // 3. åˆ†é…Passåˆ°é˜Ÿåˆ—
    assign_passes_to_queues(graph);
    
    // 4. è®¡ç®—åŒæ­¥éœ€æ±‚
    calculate_sync_requirements(graph);
    
    // 5. åˆ†é…Fenceå¯¹è±¡
    allocate_fences(graph);
    
    SKR_LOG_DEBUG(u8"ScheduleTimeline: Scheduling completed. Queues: %d, SyncRequirements: %d", 
                  (int)schedule_result.queue_schedules.size(), (int)schedule_result.sync_requirements.size());
}

void ScheduleTimeline::query_queue_capabilities(RenderGraph* graph) SKR_NOEXCEPT
{
    // æ¸…ç©ºé˜Ÿåˆ—ä¿¡æ¯
    available_queues.clear();
    graphics_queue_index = UINT32_MAX;
    compute_queue_indices.clear();
    copy_queue_indices.clear();
    
    uint32_t queue_index = 0;
    
    // æ·»åŠ Graphicsé˜Ÿåˆ—ï¼ˆæ€»æ˜¯å­˜åœ¨ï¼‰
    if (auto gfx_queue = graph->get_gfx_queue()) {
        available_queues.emplace(QueueCapabilities{
            .supports_graphics = true, .supports_compute = true, .supports_copy = true, .supports_present = true,
            .family_index = 0, .queue_handle = gfx_queue
        });
        graphics_queue_index = queue_index++;
    }
    
    // æ·»åŠ AsyncComputeé˜Ÿåˆ—ï¼ˆå¤šä¸ªï¼‰
    if (config.enable_async_compute) {
        const auto& cmpt_queues = graph->get_cmpt_queues();
        uint32_t max_compute = skr::min((uint32_t)cmpt_queues.size(), config.max_async_compute_queues);
        for (uint32_t i = 0; i < max_compute; ++i) {
            available_queues.emplace(QueueCapabilities{
                .supports_compute = true, .supports_copy = true,
                .family_index = 1, .queue_handle = cmpt_queues[i]
            });
            compute_queue_indices.add(queue_index++);
        }
    }
    
    // æ·»åŠ Copyé˜Ÿåˆ—ï¼ˆå¤šä¸ªï¼‰
    if (config.enable_copy_queue) {
        const auto& cpy_queues = graph->get_cpy_queues();
        uint32_t max_copy = skr::min((uint32_t)cpy_queues.size(), config.max_copy_queues);
        for (uint32_t i = 0; i < max_copy; ++i) {
            available_queues.emplace(QueueCapabilities{
                .supports_copy = true,
                .family_index = 2, .queue_handle = cpy_queues[i]
            });
            copy_queue_indices.add(queue_index++);
        }
    }
    
    SKR_LOG_DEBUG(u8"ScheduleTimeline: Queue capabilities - Graphics: %s, AsyncCompute: %d queues, Copy: %d queues",
                  graphics_queue_index != UINT32_MAX ? u8"âœ“" : u8"âœ—",
                  (int)compute_queue_indices.size(), (int)copy_queue_indices.size());
}

void ScheduleTimeline::analyze_dependencies(RenderGraph* graph) SKR_NOEXCEPT
{
    dependency_info.clear();
    
    auto& passes = get_passes(graph);
    
    // æ„å»ºPassçº§åˆ«çš„ä¾èµ–å›¾
    for (auto* pass : passes) {
        auto& info = dependency_info[pass];
        
        // TODO: ä»RenderGraphçš„ä¾èµ–å›¾ä¸­æå–Passä¹‹é—´çš„ç›´æ¥ä¾èµ–å…³ç³»
        // å½“å‰ç®€åŒ–å®ç°ï¼šé€šè¿‡æ‹“æ‰‘é¡ºåºæ¨å¯¼ç®€å•çš„ä¸²è¡Œä¾èµ–
        
        // è®¾ç½®é˜Ÿåˆ—äº²å’Œæ€§ - æ ¹æ®Passç±»å‹ç¡®å®šå¯è¿è¡Œçš„é˜Ÿåˆ—
        for (uint32_t i = 0; i < available_queues.size(); ++i) {
            if (can_run_on_queue_index(pass, i)) {
                // æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨å®é™…é˜Ÿåˆ—ç´¢å¼•ï¼Œè€Œä¸æ˜¯æšä¸¾ç±»å‹
                info.queue_affinities.set(i);
            }
        }
        
        // å¦‚æœPasså¯ä»¥åœ¨å¤šä¸ªé˜Ÿåˆ—ä¸Šè¿è¡Œï¼Œå°±æœ‰è·¨é˜Ÿåˆ—è°ƒåº¦çš„æ½œåŠ›
        if (info.queue_affinities.count() > 1) {
            info.has_cross_queue_dependency = true;
        }
    }
    
    // å»ºç«‹ç®€åŒ–çš„Passä¾èµ–å…³ç³» - åŸºäºPassæ·»åŠ é¡ºåºçš„ä¸²è¡Œä¾èµ–
    for (size_t i = 1; i < passes.size(); ++i) {
        auto* current_pass = passes[i];
        auto* previous_pass = passes[i - 1];
        
        // å½“å‰ç®€åŒ–å¤„ç†ï¼šæ¯ä¸ªPassä¾èµ–å‰ä¸€ä¸ªPassï¼ˆä¸¥æ ¼ä¸²è¡Œï¼‰
        // TODO: ä»RenderGraphçš„çœŸå®ä¾èµ–å›¾ä¸­è·å–æ›´ç²¾ç¡®çš„ä¾èµ–å…³ç³»
        dependency_info[current_pass].dependencies.add(previous_pass);
        dependency_info[previous_pass].dependents.add(current_pass);
    }
}

void ScheduleTimeline::classify_passes(RenderGraph* graph) SKR_NOEXCEPT
{
    auto& passes = get_passes(graph);
    
    for (auto* pass : passes) {
        // åˆ†ç±»Passå¹¶è®°å½•åˆ°Mapä¸­
        auto queue_type = classify_pass(pass);
        pass_preferred_queue[pass] = queue_type;
    }
}

ERenderGraphQueueType ScheduleTimeline::classify_pass(PassNode* pass) SKR_NOEXCEPT
{
    // 1. Present Passå¿…é¡»åœ¨Graphicsé˜Ÿåˆ—
    if (pass->pass_type == EPassType::Present) {
        return ERenderGraphQueueType::Graphics;
    }
    
    // 2. Render Passå¿…é¡»åœ¨Graphicsé˜Ÿåˆ—
    if (pass->pass_type == EPassType::Render) {
        return ERenderGraphQueueType::Graphics;
    }
    
    // 3. Copy Passä¼˜å…ˆCopyé˜Ÿåˆ—
    if (pass->pass_type == EPassType::Copy && config.enable_copy_queue) {
        auto* copy_pass = static_cast<CopyPassNode*>(pass);
        // æ£€æŸ¥æ˜¯å¦æ ‡è®°ä¸ºå¯ä»¥ç‹¬ç«‹æ‰§è¡Œ
        if (copy_pass->get_can_be_lone()) {
            // æ£€æŸ¥æ˜¯å¦çœŸçš„æ²¡æœ‰ç´§å¯†ä¾èµ–
            auto& info = dependency_info[pass];
            bool is_isolated = true;
            
            for (auto* dep : info.dependencies) {
                if (dep->pass_type == EPassType::Render) {
                    is_isolated = false;
                    break;
                }
            }
            
            if (is_isolated) {
                return ERenderGraphQueueType::Copy;
            }
        }
    }
    
    // 4. Compute Passæ£€æŸ¥å¼‚æ­¥æç¤º  
    if (pass->pass_type == EPassType::Compute && config.enable_async_compute) {
        // ç®€åŒ–å¤„ç†ï¼šå¦‚æœæ²¡æœ‰å›¾å½¢èµ„æºä¾èµ–ï¼Œå¯ä»¥å¼‚æ­¥æ‰§è¡Œ
        if (!has_graphics_resource_dependency(pass)) {
            return ERenderGraphQueueType::AsyncCompute;
        }
    }
    
    // é»˜è®¤åˆ†é…åˆ°Graphicsé˜Ÿåˆ—
    return ERenderGraphQueueType::Graphics;
}

bool ScheduleTimeline::can_run_on_queue(PassNode* pass, ERenderGraphQueueType queue) SKR_NOEXCEPT
{
    switch (queue) {
        case ERenderGraphQueueType::Graphics:
            return graphics_queue_index != UINT32_MAX && can_run_on_queue_index(pass, graphics_queue_index);
        case ERenderGraphQueueType::AsyncCompute:
            return !compute_queue_indices.is_empty() && can_run_on_queue_index(pass, compute_queue_indices[0]);
        case ERenderGraphQueueType::Copy:
            return !copy_queue_indices.is_empty() && can_run_on_queue_index(pass, copy_queue_indices[0]);
        default:
            return false;
    }
}

bool ScheduleTimeline::can_run_on_queue_index(PassNode* pass, uint32_t queue_index) SKR_NOEXCEPT
{
    if (queue_index >= available_queues.size()) return false;
    
    const auto& caps = available_queues[queue_index];
    switch (pass->pass_type) {
        case EPassType::Render:   return caps.supports_graphics;
        case EPassType::Compute:  return caps.supports_compute;
        case EPassType::Copy:     return caps.supports_copy;
        case EPassType::Present:  return caps.supports_present;
        default:                  return false;
    }
}

bool ScheduleTimeline::has_graphics_resource_dependency(PassNode* pass) SKR_NOEXCEPT
{
    bool has_graphics_dep = false;
    
    // æ£€æŸ¥çº¹ç†èµ„æº
    pass->foreach_textures([&](TextureNode* texture, TextureEdge* edge) {
        if (texture) {
            // æ£€æŸ¥æ˜¯å¦æ˜¯æ¸²æŸ“ç›®æ ‡æˆ–æ·±åº¦ç¼“å†²
            if (texture->get_desc().descriptors & CGPU_RESOURCE_TYPE_RENDER_TARGET ||
                texture->get_desc().descriptors & CGPU_RESOURCE_TYPE_DEPTH_STENCIL) {
                has_graphics_dep = true;
            }
        }
    });
    
    return has_graphics_dep;
}

void ScheduleTimeline::assign_passes_to_queues(RenderGraph* graph) SKR_NOEXCEPT
{
    // åˆå§‹åŒ–é˜Ÿåˆ—è°ƒåº¦ç»“æœ
    schedule_result.queue_schedules.clear();
    schedule_result.queue_schedules.reserve(available_queues.size());
    for (uint32_t i = 0; i < available_queues.size(); ++i) {
        const auto& caps = available_queues[i];
        auto queue_type = caps.supports_graphics ? ERenderGraphQueueType::Graphics :
                         caps.supports_compute ? ERenderGraphQueueType::AsyncCompute : ERenderGraphQueueType::Copy;
        schedule_result.queue_schedules.emplace(QueueScheduleInfo{queue_type, i});
    }
    
    // æ‹“æ‰‘æ’åºå¹¶åˆ†é…Pass
    auto sorted_passes = topological_sort_passes(get_passes(graph));
    for (auto* pass : sorted_passes) {
        uint32_t queue_idx = select_best_queue_for_pass(pass);
        schedule_result.queue_schedules[queue_idx].scheduled_passes.add(pass);
        pass_to_queue[pass] = queue_idx;
        schedule_result.pass_queue_assignments[pass] = queue_idx;
    }
}

skr::Vector<PassNode*> ScheduleTimeline::topological_sort_passes(const skr::Vector<PassNode*>& passes) SKR_NOEXCEPT
{
    skr::Vector<PassNode*> sorted_passes;
    skr::FlatHashMap<PassNode*, uint32_t> in_degree;
    skr::Vector<PassNode*> queue;
    
    // è®¡ç®—å…¥åº¦å¹¶æ”¶é›†èµ·å§‹èŠ‚ç‚¹
    for (auto* pass : passes) {
        uint32_t degree = dependency_info[pass].dependencies.size();
        in_degree[pass] = degree;
        if (degree == 0) queue.add(pass);
    }
    
    // æ‹“æ‰‘æ’åº
    while (!queue.is_empty()) {
        auto* pass = queue.back();
        queue.pop_back();
        sorted_passes.add(pass);
        
        for (auto* dependent : dependency_info[pass].dependents) {
            if (--in_degree[dependent] == 0) {
                queue.add(dependent);
            }
        }
    }
    
    return sorted_passes;
}


uint32_t ScheduleTimeline::select_best_queue_for_pass(PassNode* pass) SKR_NOEXCEPT
{
    auto preferred_type = pass_preferred_queue[pass];
    
    // æ ¹æ®åå¥½ç±»å‹é€‰æ‹©é˜Ÿåˆ—
    switch (preferred_type) {
        case ERenderGraphQueueType::AsyncCompute:
            if (!compute_queue_indices.is_empty()) {
                return find_least_loaded_compute_queue();
            }
            break;
        case ERenderGraphQueueType::Copy:
            if (!copy_queue_indices.is_empty()) {
                return copy_queue_indices[0];
            }
            break;
        default:
            break;
    }
    
    // é»˜è®¤å›é€€åˆ°Graphicsé˜Ÿåˆ—
    return graphics_queue_index;
}


uint32_t ScheduleTimeline::find_least_loaded_compute_queue() SKR_NOEXCEPT
{
    if (compute_queue_indices.is_empty()) {
        return graphics_queue_index; // å›é€€åˆ°Graphicsé˜Ÿåˆ—
    }
    
    // æ‰¾åˆ°è´Ÿè½½æœ€å°çš„è®¡ç®—é˜Ÿåˆ—
    uint32_t best_queue = compute_queue_indices[0];
    size_t min_load = SIZE_MAX;
    
    for (uint32_t queue_idx : compute_queue_indices) {
        if (queue_idx < schedule_result.queue_schedules.size()) {
            size_t current_load = schedule_result.queue_schedules[queue_idx].scheduled_passes.size();
            if (current_load < min_load) {
                min_load = current_load;
                best_queue = queue_idx;
            }
        }
    }
    
    return best_queue;
}

bool ScheduleTimeline::is_compute_queue(uint32_t queue_index) const SKR_NOEXCEPT
{
    for (uint32_t compute_idx : compute_queue_indices) {
        if (compute_idx == queue_index) {
            return true;
        }
    }
    return false;
}

void ScheduleTimeline::calculate_sync_requirements(RenderGraph* graph) SKR_NOEXCEPT
{
    schedule_result.sync_requirements.clear();
    
    // æ”¶é›†è·¨é˜Ÿåˆ—ä¾èµ–å¹¶ç›´æ¥ç”ŸæˆåŒæ­¥éœ€æ±‚
    skr::FlatHashMap<uint64_t, SyncRequirement> sync_map;
    
    for (auto& [pass, queue] : pass_to_queue) {
        for (auto* dep : dependency_info[pass].dependencies) {
            auto dep_queue = pass_to_queue[dep];
            if (dep_queue != queue) {
                uint64_t key = ((uint64_t)dep_queue << 32) | queue;
                auto& requirement = sync_map[key];
                requirement.signal_queue_index = dep_queue;
                requirement.wait_queue_index = queue;
                requirement.signal_after_pass = dep;
                requirement.wait_before_pass = pass;
                requirement.fence = nullptr;
            }
        }
    }
    
    // è½¬æ¢ä¸ºvector
    schedule_result.sync_requirements.reserve(sync_map.size());
    for (auto& [key, requirement] : sync_map) {
        schedule_result.sync_requirements.add(requirement);
    }
}


void ScheduleTimeline::allocate_fences(RenderGraph* graph) SKR_NOEXCEPT
{
    auto device = graph->get_backend_device();
    if (!device) {
        SKR_LOG_WARN(u8"ScheduleTimeline: No backend device available for fence allocation");
        return;
    }
    
    // ä¸ºæ¯ä¸ªåŒæ­¥éœ€æ±‚åˆ†é…CGPUFenceå¯¹è±¡
    for (auto& requirement : schedule_result.sync_requirements) {
        if (!requirement.fence) {
            requirement.fence = cgpu_create_fence(device);
            
            SKR_LOG_DEBUG(u8"ScheduleTimeline: Allocated fence for sync between queue %d->%d (pass %p->%p)", 
                         requirement.signal_queue_index, requirement.wait_queue_index,
                         requirement.signal_after_pass, requirement.wait_before_pass);
        }
    }
    
    SKR_LOG_DEBUG(u8"ScheduleTimeline: Allocated %d fences for cross-queue synchronization", 
                  (int)schedule_result.sync_requirements.size());
}

void ScheduleTimeline::dump_timeline_result(const char8_t* title) const SKR_NOEXCEPT
{
    SKR_LOG_INFO(u8"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    SKR_LOG_INFO(u8"%s", title);
    SKR_LOG_INFO(u8"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    
    // æ‰“å°é˜Ÿåˆ—è°ƒåº¦ä¿¡æ¯
    SKR_LOG_INFO(u8"ğŸ“… Queue Schedules (%d queues):", (int)schedule_result.queue_schedules.size());
    for (size_t i = 0; i < schedule_result.queue_schedules.size(); ++i) {
        const auto& queue_schedule = schedule_result.queue_schedules[i];
        const char8_t* queue_name = get_queue_type_name(queue_schedule.queue_type);
        
        // ä¸ºå¤šé˜Ÿåˆ—ç±»å‹æ·»åŠ ç´¢å¼•æ ‡è¯†
        skr::String queue_display_name;
        if (queue_schedule.queue_type == ERenderGraphQueueType::AsyncCompute && compute_queue_indices.size() > 1) {
            uint32_t index = compute_queue_indices.find(i).index();
            queue_display_name = skr::format(u8"{}#{}", queue_name, index);
        } else {
            queue_display_name = skr::String(queue_name);
        }
        
        SKR_LOG_INFO(u8"  [%zu] %s Queue (index=%d, %d passes):", 
                     i, queue_display_name.c_str(), queue_schedule.queue_index, 
                     (int)queue_schedule.scheduled_passes.size());
        
        for (size_t j = 0; j < queue_schedule.scheduled_passes.size(); ++j) {
            auto* pass = queue_schedule.scheduled_passes[j];
            const char8_t* pass_type_name = u8"Unknown";
            
            switch (pass->pass_type) {
                case EPassType::Render: pass_type_name = u8"Render"; break;
                case EPassType::Compute: pass_type_name = u8"Compute"; break;
                case EPassType::Copy: pass_type_name = u8"Copy"; break;
                case EPassType::Present: pass_type_name = u8"Present"; break;
            }
            
            SKR_LOG_INFO(u8"    [%zu] %s Pass (name=%s)", j, pass_type_name, pass->get_name());
        }
    }
    
    // æ‰“å°åŒæ­¥éœ€æ±‚
    SKR_LOG_INFO(u8"");
    SKR_LOG_INFO(u8"ğŸ”„ Sync Requirements (%d requirements):", (int)schedule_result.sync_requirements.size());
    
    if (schedule_result.sync_requirements.is_empty()) {
        SKR_LOG_INFO(u8"  âœ… No cross-queue synchronization needed");
    } else {
        for (size_t i = 0; i < schedule_result.sync_requirements.size(); ++i) {
            const auto& requirement = schedule_result.sync_requirements[i];
            
            const char8_t* signal_queue_name = u8"Unknown";
            const char8_t* wait_queue_name = u8"Unknown";
            
            if (requirement.signal_queue_index < schedule_result.queue_schedules.size()) {
                signal_queue_name = get_queue_type_name(schedule_result.queue_schedules[requirement.signal_queue_index].queue_type);
            }
            if (requirement.wait_queue_index < schedule_result.queue_schedules.size()) {
                wait_queue_name = get_queue_type_name(schedule_result.queue_schedules[requirement.wait_queue_index].queue_type);
            }
            
            SKR_LOG_INFO(u8"  [%zu] %s[%d] --signal--> %s[%d]", 
                         i, signal_queue_name, requirement.signal_queue_index,
                         wait_queue_name, requirement.wait_queue_index);
            SKR_LOG_INFO(u8"       Signal after: %s, Wait before: %s, Fence: %p",
                         requirement.signal_after_pass->get_name(), requirement.wait_before_pass->get_name(), requirement.fence);
        }
    }
    
    // æ‰“å°Passæ˜ å°„ç»Ÿè®¡
    SKR_LOG_INFO(u8"");
    SKR_LOG_INFO(u8"ğŸ“Š Pass Assignment Summary:");
    
    uint32_t graphics_count = 0, compute_count = 0, copy_count = 0;
    for (const auto& [pass, queue_idx] : schedule_result.pass_queue_assignments) {
        if (queue_idx < schedule_result.queue_schedules.size()) {
            auto queue_type = schedule_result.queue_schedules[queue_idx].queue_type;
            switch (queue_type) {
                case ERenderGraphQueueType::Graphics: graphics_count++; break;
                case ERenderGraphQueueType::AsyncCompute: compute_count++; break;
                case ERenderGraphQueueType::Copy: copy_count++; break;
            }
        }
    }
    
    SKR_LOG_INFO(u8"  ğŸ“ˆ Graphics Queue: %d passes", graphics_count);
    SKR_LOG_INFO(u8"  âš¡ AsyncCompute Queue: %d passes", compute_count);
    SKR_LOG_INFO(u8"  ğŸ“ Copy Queue: %d passes", copy_count);
    SKR_LOG_INFO(u8"  ğŸ“ Total Passes: %d", (int)schedule_result.pass_queue_assignments.size());
    
    SKR_LOG_INFO(u8"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
}

} // namespace render_graph
} // namespace skr